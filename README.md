[//]: # (Image References)

[image1]: ./images/Train_track.png "Image Caption"


[image2]: ./images/beach.png "Image Caption"

[image3]: ./images/bear.png "Image Caption"

[image4]: ./images/cat_window.png "Image Caption"

[image5]: ./images/baseball.png "Image Caption"


# Image Captioning

## Overview

Neural network architecture to automatically generate captions from images.

Microsoft Common Objects in COntext (MS COCO) dataset is used to train the network

## Instructions

There are four series of jupyter notebook

* 0_Dataset.ipynb
* 1_Preliminaries.ipynb
* 2_Training.ipynb
* 3_Inference.ipynb


**You MUST use GPU for this project**

A completely trained model is expected to take between 5-12 hours to train well on a GPU; it is suggested that you look at early patterns in loss (what happens in the first hour or so of training) as you make changes to your model, so that you only have to spend this large amount of time training your final model.

## Caption genetated for some of the images by the model 

![Image Caption][image1]
a train is coming down the tracks at a station . . . 


![Image Caption][image2]
a group of people on a beach flying a kite . . .

![Image Caption][image3]
a bear that is standing in the grass . . .

![Image Caption][image4]
a cat sitting on a window sill looking out the window . . .

![Image Caption][image5]
a baseball player is swinging a bat at a ball . . . 


LICENSE: This project is licensed under the terms of the MIT license.
